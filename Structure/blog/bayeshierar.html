<!DOCTYPE html><html lang="en"><head><title>Blog</title><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="stylesheet" type="text/css" href="../CSS_layout.css" media="screen" /><style></style></head><body><div class="navbar"><a float=left href="../index.html" class="left">ðŸŒ¿ Home</a><a href="../blog.html">Blog</a></div><div class="blog">


  <h2>Bayesian hierarchical modeling </h2>
    <p align="justify"> As a rule of thumb, if you have less than 100 observations
      and not a lot of trials, machine learning is not likely to perform well.
      If on top, you have a lot of variables (e.g., age, weight, sex, etc...),
      you are likely to face the multiple comparisons problem if using classical statistics.</p>
    <p align="justify"> The Bayesian hierarchical modeling estimates the parameters
      of the posterior distribution using the Bayesian method. "Hierarchical" because information
      is available on several different levels of observational units and we want to separately
      estimate the posterior distribution of each individual predictor and its group-level effects.</p>
    <p align="justify"> The Bayesian hierarchical modeling is useful in case of nested data.
      And we can consider that every dataset is kind of nested. Let's say you have a control
      group of heatlhy subjects, they could still be divided into subgroups (per gender, age, etc...).
      Hierarchical modeling is perfectly adapted to such setting. It fits to dataset with more
      parameters than observations. Prof. Gelman suggested to use the Bayesian hierarchical modeling
      by default.</p>
    <p align="justify"> Nowadays, we have a much richer description of people =>
      more meta-information than before which explains why the Bayesian hierarchical
      modeling is emerging. In psychiatry, location is a nested hidden variable rarely
      exploited. The dataset size is usually quite small and by dividing your sample
      into subsamples, the risk of overfitting is increased because of the lack of data.
      Using a frequentist or a machine learning approach would not deal well with the
      information lost. Using the Bayesian hierarchical modeling improves the parameter
      estimates and reduce the risk of overfitting. It shares the statistical strength
      by doing partial pooling. </p>
    <p align="justify">Great introduction to hierarchical modeling: http://mfviz.com/hierarchical-models/</p>
    <p align="justify">More info on multilevel modeling by Andrew Gelman: <a href="http://www.stat.columbia.edu/~gelman/research/published/multi2.pdf/" target="_blank">Link</a></p>
    <p align="justify">The Bayesian hierarchical modeling page on Wikipedia is also great: <a href="https://en.wikipedia.org/wiki/Bayesian_hierarchical_modeling" target="_blank">Link</a></p>




</div></body></html>